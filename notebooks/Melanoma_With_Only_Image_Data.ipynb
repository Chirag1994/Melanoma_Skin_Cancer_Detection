{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing External Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:12.345420Z",
     "iopub.status.busy": "2023-04-14T03:47:12.345019Z",
     "iopub.status.idle": "2023-04-14T03:47:22.213814Z",
     "shell.execute_reply": "2023-04-14T03:47:22.212619Z",
     "shell.execute_reply.started": "2023-04-14T03:47:12.345375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:23.627821Z",
     "iopub.status.busy": "2023-04-14T03:47:23.627075Z",
     "iopub.status.idle": "2023-04-14T03:47:29.034312Z",
     "shell.execute_reply": "2023-04-14T03:47:29.032841Z",
     "shell.execute_reply.started": "2023-04-14T03:47:23.627778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0 0.14.0\n"
     ]
    }
   ],
   "source": [
    "################ Importing Libraries ################\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "import torch.cuda.amp as amp\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFile\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from timeit import default_timer as timer\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "!mkdir Models\n",
    "\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "print(torch.__version__, torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:29.038752Z",
     "iopub.status.busy": "2023-04-14T03:47:29.038026Z",
     "iopub.status.idle": "2023-04-14T03:47:29.161501Z",
     "shell.execute_reply": "2023-04-14T03:47:29.160527Z",
     "shell.execute_reply.started": "2023-04-14T03:47:29.038715Z"
    }
   },
   "outputs": [],
   "source": [
    "## Configuration Settings ##\n",
    "\n",
    "class Config:\n",
    "        \n",
    "    EPOCHS = 20\n",
    "    IMG_SIZE = 512\n",
    "    RESOLUTION = 456\n",
    "    ES_PATIENCE = 2\n",
    "    WEIGHT_DECAY = 0.001\n",
    "    VAL_BATCH_SIZE = 32 * 2\n",
    "    RANDOM_STATE = 1994\n",
    "    LEARNING_RATE = 5e-5\n",
    "    TRAIN_BATCH_SIZE = 32\n",
    "    MEAN = (0.485, 0.456, 0.406)\n",
    "    STD = (0.229, 0.224, 0.225)\n",
    "    TRAIN_COLS = [\"image_name\", \"patient_id\", \"sex\", \"age_approx\", \"anatom_site_general_challenge\",\n",
    "                 \"target\", \"tfrecord\"]\n",
    "    TEST_COLS = [\"image_name\", \"patient_id\", \"sex\", \"age_approx\", \"anatom_site_general_challenge\"]\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    ################ Setting paths to data input ################\n",
    "    \n",
    "    data_2020 = \"/kaggle/input/jpeg-melanoma-512x512/\"\n",
    "    train_folder_2020 = data_2020 + \"train/\"\n",
    "    test_folder_2020 = data_2020 + \"test/\"\n",
    "    test_csv_path_2020 = data_2020 + \"test.csv\"\n",
    "    train_csv_path_2020 = data_2020 + \"train.csv\"\n",
    "    submission_csv_path = data_2020 + \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:29.164497Z",
     "iopub.status.busy": "2023-04-14T03:47:29.163519Z",
     "iopub.status.idle": "2023-04-14T03:47:29.181671Z",
     "shell.execute_reply": "2023-04-14T03:47:29.180597Z",
     "shell.execute_reply.started": "2023-04-14T03:47:29.164444Z"
    }
   },
   "outputs": [],
   "source": [
    "## Helper Utilities\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\n",
    "       Directly borrowed from https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\"\"\"\n",
    "    def __init__(self, path, patience=7, verbose=False, delta=0, trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "            \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(obj=model.state_dict(), f=self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "def plot_loss_curves(results):\n",
    "    \"\"\"\n",
    "    Function to plot training & validation loss curves & validation AUC\n",
    "    \"\"\"\n",
    "    loss = results['train_loss']\n",
    "    valid_loss = results['valid_loss']\n",
    "    # Get the accuracy values of the results dictionary (training and test)\n",
    "    valid_auc = results['valid_auc']\n",
    "    # Figure out how many epochs there were\n",
    "    epochs = range(len(results['train_loss']))\n",
    "    # Setup a plot \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='train_loss')\n",
    "    plt.plot(epochs, valid_loss, label='valid_loss')\n",
    "    plt.title('Loss'); plt.xlabel('Epochs');plt.legend()\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, valid_auc, label='valid_auc')\n",
    "    plt.title('AUC Score'); plt.xlabel('Epochs'); plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:29.185675Z",
     "iopub.status.busy": "2023-04-14T03:47:29.185415Z",
     "iopub.status.idle": "2023-04-14T03:47:29.199800Z",
     "shell.execute_reply": "2023-04-14T03:47:29.198734Z",
     "shell.execute_reply.started": "2023-04-14T03:47:29.185649Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating Dataset classes to load the images\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class DatasetRetriever(nn.Module):\n",
    "    def __init__(self, df, tabular_features=None, use_tabular_features=False,\n",
    "                augmentations=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.tabular_features = tabular_features\n",
    "        self.use_tabular_features = use_tabular_features\n",
    "        self.augmentations = augmentations\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.df['image_path'].iloc[index]\n",
    "        image = Image.open(image_path)\n",
    "        image = np.array(image)\n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']\n",
    "        image = np.transpose(image, (2,0,1)).astype(np.float32)\n",
    "        image = torch.tensor(image, dtype=torch.float)\n",
    "        if self.use_tabular_features:\n",
    "            if len(self.tabular_features) > 0 and self.is_test == False:\n",
    "                tabular_features = np.array(self.df.iloc[index][self.tabular_features].values, dtype=np.float32)\n",
    "                targets = self.df.target[index]\n",
    "                return {\"image\": image, \"tabular_features\": tabular_features, \"targets\": torch.tensor(targets, dtype=torch.long)}\n",
    "            elif len(self.tabular_features) > 0 and self.is_test == True:\n",
    "                tabular_features = np.array(self.df.iloc[index][self.tabular_features].values, dtype=np.float32)\n",
    "                return {\"image\": image, \"tabular_features\": tabular_features}\n",
    "        else:\n",
    "            if self.is_test == False:\n",
    "                targets = self.df.target[index]\n",
    "                return {\"image\" : image, \"targets\": torch.tensor(targets, dtype=torch.long)}\n",
    "            elif self.is_test == True:\n",
    "                return {\"image\": image}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluate Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:29.202763Z",
     "iopub.status.busy": "2023-04-14T03:47:29.201173Z",
     "iopub.status.idle": "2023-04-14T03:47:29.224176Z",
     "shell.execute_reply": "2023-04-14T03:47:29.223127Z",
     "shell.execute_reply.started": "2023-04-14T03:47:29.202724Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, loss_fn, optimizer, device, scaler, use_tabular_features=False):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        if use_tabular_features:\n",
    "            if batch == 0:\n",
    "                print(\"Using meta features\")\n",
    "            data[\"image\"], data[\"meta_features\"], data['targets'] = data[\"image\"].to(device, dtype=torch.float), \\\n",
    "                    data[\"meta_features\"].to(device, dtype=torch.float), data['targets'].to(device, dtype=torch.float)\n",
    "        else:\n",
    "            if batch == 0:\n",
    "                print(\"Not using meta features\")\n",
    "            data[\"image\"], data['targets'] = data[\"image\"].to(device, dtype=torch.float), data['targets'].to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        with amp.autocast():\n",
    "            y_logits = model(data['image']).squeeze(dim=0)\n",
    "            loss = loss_fn(y_logits, data[\"targets\"].view(-1,1))\n",
    "        train_loss += loss.item()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()        \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "def validate_one_epoch(model, dataloader, loss_fn, device, use_tabular_features=False):\n",
    "    valid_loss, final_predictions = 0, []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, data in enumerate(dataloader):\n",
    "            if use_tabular_features:\n",
    "                if batch == 0:\n",
    "                    print(\"Using meta features\")\n",
    "                data[\"image\"], data[\"meta_features\"], data['targets'] = data[\"image\"].to(device, dtype=torch.float), \\\n",
    "                    data[\"meta_features\"].to(device, dtype=torch.float), data['targets'].to(device, dtype=torch.float)\n",
    "            else:\n",
    "                if batch == 0:\n",
    "                    print(\"Not using meta features\")\n",
    "                data[\"image\"], data['targets'] = data[\"image\"].to(device, dtype=torch.float), data['targets'].to(device, dtype=torch.float)    \n",
    "            y_logits = model(data['image']).squeeze(dim=0)\n",
    "            loss = loss_fn(y_logits, data[\"targets\"].view(-1,1))\n",
    "            valid_loss += loss.item()\n",
    "            valid_probs = torch.sigmoid(y_logits).detach().cpu().numpy().tolist()\n",
    "            final_predictions.extend(valid_probs)\n",
    "    valid_loss = valid_loss / len(dataloader)\n",
    "    return valid_loss, final_predictions\n",
    "\n",
    "def train(model, train_dataloader, valid_dataloader, loss_fn, optimizer, scheduler,\n",
    "          device, scaler, epochs, es_patience, model_save_path, validation_targets):\n",
    "    results = {\"train_loss\": [], \"valid_loss\": [], \"valid_auc\": []}\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=es_patience, verbose=True, path=model_save_path)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = train_one_epoch(model=model, dataloader=train_dataloader,\n",
    "                                    loss_fn=loss_fn, optimizer=optimizer,\n",
    "                                    device=device, scaler=scaler)\n",
    "        \n",
    "        valid_loss, valid_predictions = validate_one_epoch(model=model, \n",
    "                                    dataloader=valid_dataloader, loss_fn=loss_fn, device=device)\n",
    "        \n",
    "        valid_predictions = np.vstack(valid_predictions).ravel()\n",
    "        \n",
    "        valid_auc = roc_auc_score(y_score=valid_predictions, \n",
    "                                  y_true=validation_targets)\n",
    "        scheduler.step(valid_auc)\n",
    "        \n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early Stopping\")\n",
    "            break\n",
    "            \n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        print(f\"Epoch : {epoch+1} | \"\n",
    "              f\"train_loss : {train_loss:.4f} | \"\n",
    "              f\"valid_loss : {valid_loss:.4f} | \"\n",
    "              f\"valid_auc : {valid_auc:.4f} \")\n",
    "        results['train_loss'].append(train_loss)\n",
    "        results['valid_loss'].append(valid_loss)\n",
    "        results['valid_auc'].append(valid_auc)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:29.226267Z",
     "iopub.status.busy": "2023-04-14T03:47:29.225373Z",
     "iopub.status.idle": "2023-04-14T03:47:29.240387Z",
     "shell.execute_reply": "2023-04-14T03:47:29.239372Z",
     "shell.execute_reply.started": "2023-04-14T03:47:29.226231Z"
    }
   },
   "outputs": [],
   "source": [
    "## Setting Training & Validation Augmentations\n",
    "\n",
    "training_augmentations = A.Compose([A.CoarseDropout(p=0.6),\n",
    "                                    A.RandomRotate90(p=0.6),\n",
    "                                    A.Flip(p=0.4),\n",
    "                                    A.OneOf([A.RandomBrightnessContrast(brightness_limit=0.2,\n",
    "                                                                       contrast_limit=0.3),\n",
    "                                            A.HueSaturationValue(hue_shift_limit=20,\n",
    "                                                                sat_shift_limit=60,\n",
    "                                                                val_shift_limit=50)], p=0.7),\n",
    "                                    A.OneOf([A.GaussianBlur(),\n",
    "                                            A.GaussNoise()], p=0.65),\n",
    "                                    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.35, rotate_limit=45, p=0.5),\n",
    "                                    A.OneOf([A.OpticalDistortion(p=0.3),\n",
    "                                            A.GridDistortion(p=0.1),\n",
    "                                            A.PiecewiseAffine(p=0.3)], p=0.7),\n",
    "    A.Normalize(mean=Config.MEAN, std=Config.STD,\n",
    "                max_pixel_value=255.0, always_apply=True)\n",
    "])\n",
    "\n",
    "validation_augmentations = A.Compose([A.Normalize(mean=Config.MEAN, std=Config.STD, \n",
    "                                        max_pixel_value=255.0,always_apply=True)\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:29.242202Z",
     "iopub.status.busy": "2023-04-14T03:47:29.241782Z",
     "iopub.status.idle": "2023-04-14T03:47:29.254983Z",
     "shell.execute_reply": "2023-04-14T03:47:29.253992Z",
     "shell.execute_reply.started": "2023-04-14T03:47:29.242167Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,model_name='efficientnet-b5',pool_type=F.adaptive_avg_pool2d):\n",
    "        super().__init__()\n",
    "        self.pool_type = pool_type\n",
    "        self.model_name = model_name\n",
    "        self.backbone = EfficientNet.from_pretrained(model_name)\n",
    "        in_features = getattr(self.backbone,'_fc').in_features\n",
    "        self.classifier = nn.Linear(in_features,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        features = self.pool_type(self.backbone.extract_features(x),1)\n",
    "        features = features.view(x.size(0),-1)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:29.257224Z",
     "iopub.status.busy": "2023-04-14T03:47:29.256764Z",
     "iopub.status.idle": "2023-04-14T03:47:29.415343Z",
     "shell.execute_reply": "2023-04-14T03:47:29.414172Z",
     "shell.execute_reply.started": "2023-04-14T03:47:29.257100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data points & Columns in Training dataset are - (33126, 7)\n",
      "\n",
      "Number of Data points & Columns in 2020 Testing dataset are - (10982, 5)\n",
      "\n",
      "Train Dataset Columns: ['image_name', 'patient_id', 'sex', 'age_approx', 'anatom_site_general_challenge', 'target', 'tfrecord']\n",
      "\n",
      "Test Dataset Columns: ['image_name', 'patient_id', 'sex', 'age_approx', 'anatom_site_general_challenge']\n",
      "\n",
      "Distribution of Target feature in training dataset are: \n",
      "0    98.237034\n",
      "1     1.762966\n",
      "Name: target, dtype: float64\n",
      "\n",
      "**********************************************************************\n",
      "\n",
      "Distribution of sex feature in training dataset are:\n",
      "male      51.560708\n",
      "female    48.243072\n",
      "NaN        0.196220\n",
      "Name: sex, dtype: float64\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Distribution of sex feature in testing dataset are:\n",
      "male      56.956838\n",
      "female    43.043162\n",
      "Name: sex, dtype: float64\n",
      "\n",
      "Distribution of anatom_site_general_challenge feature in training dataset are:\n",
      "\n",
      "torso              50.851295\n",
      "lower extremity    25.409044\n",
      "upper extremity    15.042565\n",
      "head/neck           5.599831\n",
      "NaN                 1.590895\n",
      "palms/soles         1.132041\n",
      "oral/genital        0.374328\n",
      "Name: anatom_site_general_challenge, dtype: float64\n",
      "\n",
      "**********************************************************************\n",
      "\n",
      "Distribution of anatom_site_general_challenge feature in testing dataset are:\n",
      "\n",
      "torso              53.241668\n",
      "lower extremity    22.773630\n",
      "upper extremity    14.323438\n",
      "head/neck           5.244946\n",
      "NaN                 3.196139\n",
      "palms/soles         0.983427\n",
      "oral/genital        0.236751\n",
      "Name: anatom_site_general_challenge, dtype: float64\n",
      "**********************************************************************\n",
      "\n",
      "------------------- Missing values distribution in training dataset-------------------:\n",
      "image_name                         0\n",
      "patient_id                         0\n",
      "sex                               65\n",
      "age_approx                        68\n",
      "anatom_site_general_challenge    527\n",
      "target                             0\n",
      "tfrecord                           0\n",
      "dtype: int64\n",
      "\n",
      "-------------------Missing values distribution in testing dataset-------------------:\n",
      "image_name                         0\n",
      "patient_id                         0\n",
      "sex                                0\n",
      "age_approx                         0\n",
      "anatom_site_general_challenge    351\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Viewing Training Dataset below\n",
      "\n",
      "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  target  tfrecord\n",
      "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck       0         0\n",
      "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity       0         0\n",
      "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity       0         6\n",
      "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck       0         0\n",
      "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity       0        11\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Viewing Testing Dataset below\n",
      "\n",
      "     image_name  patient_id     sex  age_approx anatom_site_general_challenge\n",
      "0  ISIC_0052060  IP_3579794    male        70.0                           NaN\n",
      "1  ISIC_0052349  IP_7782715    male        40.0               lower extremity\n",
      "2  ISIC_0058510  IP_7960270  female        55.0                         torso\n",
      "3  ISIC_0073313  IP_6375035  female        50.0                         torso\n",
      "4  ISIC_0073502  IP_0589375  female        45.0               lower extremity\n"
     ]
    }
   ],
   "source": [
    "## Looking at the Data\n",
    "\n",
    "train_df = pd.read_csv(Config.train_csv_path_2020,\n",
    "                       usecols=Config.TRAIN_COLS)\n",
    "print(f\"Number of Data points & Columns in Training dataset are - {train_df.shape}\\n\")\n",
    "\n",
    "test_df = pd.read_csv(Config.test_csv_path_2020,\n",
    "                       usecols=Config.TEST_COLS)\n",
    "print(f\"Number of Data points & Columns in 2020 Testing dataset are - {test_df.shape}\\n\")\n",
    "\n",
    "print(f\"Train Dataset Columns: {Config.TRAIN_COLS}\\n\")\n",
    "print(f\"Test Dataset Columns: {Config.TEST_COLS}\\n\")\n",
    "\n",
    "print(f\"Distribution of Target feature in training dataset are: \\n{train_df['target'].value_counts(normalize=True) * 100}\\n\")\n",
    "print(\"*\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"Distribution of sex feature in training dataset are:\\n{train_df['sex'].value_counts(normalize=True, dropna=False) * 100}\\n\")\n",
    "print(\"*\"*50 + \"\\n\")\n",
    "print(f\"Distribution of sex feature in testing dataset are:\\n{test_df['sex'].value_counts(normalize=True, dropna=False) * 100}\\n\")\n",
    "\n",
    "print(f\"Distribution of anatom_site_general_challenge feature in training dataset are:\\n\\n{train_df['anatom_site_general_challenge'].value_counts(normalize=True, dropna=False) * 100}\\n\")\n",
    "print(\"*\"*70 + \"\\n\")\n",
    "print(f\"Distribution of anatom_site_general_challenge feature in testing dataset are:\\n\\n{test_df['anatom_site_general_challenge'].value_counts(normalize=True, dropna=False) * 100}\")\n",
    "print(\"*\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"------------------- Missing values distribution in training dataset-------------------:\\n{train_df.isnull().sum()}\\n\")\n",
    "print(f\"-------------------Missing values distribution in testing dataset-------------------:\\n{test_df.isnull().sum()}\\n\")\n",
    "\n",
    "print('\\n\\nViewing Training Dataset below\\n')\n",
    "print(train_df.head())\n",
    "print(\"*\"*100 + \"\\n\")\n",
    "print('\\n\\nViewing Testing Dataset below\\n')\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:29.417574Z",
     "iopub.status.busy": "2023-04-14T03:47:29.417168Z",
     "iopub.status.idle": "2023-04-14T03:47:29.423478Z",
     "shell.execute_reply": "2023-04-14T03:47:29.422253Z",
     "shell.execute_reply.started": "2023-04-14T03:47:29.417533Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_folds(train_df=train_df):\n",
    "    train_df = train_df.loc[train_df['tfrecord'] != -1].reset_index(drop=True)\n",
    "    train_df['fold'] = train_df['tfrecord'] % 5\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:30.636860Z",
     "iopub.status.busy": "2023-04-14T03:47:30.636269Z",
     "iopub.status.idle": "2023-04-14T03:47:30.669841Z",
     "shell.execute_reply": "2023-04-14T03:47:30.668685Z",
     "shell.execute_reply.started": "2023-04-14T03:47:30.636821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>target</th>\n",
       "      <th>tfrecord</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/jpeg-melanoma-512x512/train/ISIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/jpeg-melanoma-512x512/train/ISIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>/kaggle/input/jpeg-melanoma-512x512/train/ISIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/jpeg-melanoma-512x512/train/ISIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>/kaggle/input/jpeg-melanoma-512x512/train/ISIC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  target  tfrecord                                         image_path\n",
       "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck       0         0  /kaggle/input/jpeg-melanoma-512x512/train/ISIC...\n",
       "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity       0         0  /kaggle/input/jpeg-melanoma-512x512/train/ISIC...\n",
       "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity       0         6  /kaggle/input/jpeg-melanoma-512x512/train/ISIC...\n",
       "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck       0         0  /kaggle/input/jpeg-melanoma-512x512/train/ISIC...\n",
       "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity       0        11  /kaggle/input/jpeg-melanoma-512x512/train/ISIC..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating Image_Path for each images in 2019 & 2020 training datasets\n",
    "train_df['image_path'] = os.path.join(Config.train_folder_2020) + train_df['image_name'] + \".jpg\"\n",
    "test_df['image_path'] = os.path.join(Config.test_folder_2020) + test_df['image_name'] + \".jpg\"\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:31.629692Z",
     "iopub.status.busy": "2023-04-14T03:47:31.628967Z",
     "iopub.status.idle": "2023-04-14T03:47:31.642446Z",
     "shell.execute_reply": "2023-04-14T03:47:31.640827Z",
     "shell.execute_reply.started": "2023-04-14T03:47:31.629651Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_model(fold, train_df):\n",
    "    train_df = create_folds(train_df=train_df)\n",
    "    train_data = train_df.loc[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_data = train_df.loc[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    validation_targets = valid_data['target']\n",
    "    train_dataset = DatasetRetriever(df=train_data, tabular_features=None, use_tabular_features=False, \n",
    "                     augmentations=training_augmentations, is_test=False)\n",
    "    valid_dataset = DatasetRetriever(df=valid_data, tabular_features=None, use_tabular_features=False, \n",
    "                     augmentations=validation_augmentations, is_test=False)\n",
    "    training_dataloader = DataLoader(dataset=train_dataset, batch_size=Config.TRAIN_BATCH_SIZE, \n",
    "                                     shuffle=True, num_workers=os.cpu_count())\n",
    "    validation_dataloader = DataLoader(dataset=valid_dataset, batch_size=Config.VAL_BATCH_SIZE,\n",
    "                                       shuffle=False, num_workers=os.cpu_count())\n",
    "    seed_everything(Config.RANDOM_STATE)\n",
    "    if torch.cuda.device_count() in (0,1):\n",
    "        model = Model().to(Config.DEVICE)\n",
    "    elif torch.cuda.device_count() > 1:\n",
    "        model = Model().to(Config.DEVICE)\n",
    "        model = nn.DataParallel(model)\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=Config.LEARNING_RATE, weight_decay=Config.WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, \n",
    "                                    mode='max', factor=0.2, patience=2, \n",
    "                                    threshold=1e-3,verbose=True)\n",
    "    scaler = amp.GradScaler()\n",
    "    start_time = timer()\n",
    "    model_save_path = f\"Models/efficientnet_b5_checkpoint_fold_{fold}.pt\"\n",
    "    model_results = train(model=model, train_dataloader=training_dataloader, \n",
    "                            valid_dataloader=validation_dataloader,\n",
    "                            loss_fn = loss, optimizer=optimizer, scheduler=scheduler,\n",
    "                            device=Config.DEVICE, scaler=scaler,\n",
    "                            epochs=Config.EPOCHS, es_patience=2, \n",
    "    model_save_path=model_save_path, validation_targets=validation_targets)\n",
    "    end_time = timer()\n",
    "    print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:32.116624Z",
     "iopub.status.busy": "2023-04-14T03:47:32.116250Z",
     "iopub.status.idle": "2023-04-14T03:47:32.130338Z",
     "shell.execute_reply": "2023-04-14T03:47:32.129310Z",
     "shell.execute_reply.started": "2023-04-14T03:47:32.116591Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(fold, train_df):\n",
    "    full_train_df = create_folds(train_df)\n",
    "    valid_data = full_train_df.loc[full_train_df['fold'] == fold].reset_index(drop=True)\n",
    "    validation_targets = valid_data['target']\n",
    "    valid_dataset = DatasetRetriever(df=valid_data, tabular_features=None, use_tabular_features=False, \n",
    "                     augmentations=validation_augmentations, is_test=False)\n",
    "    validation_dataloader = DataLoader(dataset=valid_dataset, batch_size=Config.VAL_BATCH_SIZE,\n",
    "                                       shuffle=False, num_workers=os.cpu_count())\n",
    "    valid_predictions = []\n",
    "    if torch.cuda.device_count() in (0,1):\n",
    "        EfficientNetB0_trained_model = Model().to(Config.DEVICE)\n",
    "    elif torch.cuda.device_count() > 1:\n",
    "        EfficientNetB0_trained_model = Model().to(Config.DEVICE)\n",
    "        EfficientNetB0_trained_model = nn.DataParallel(EfficientNetB0_trained_model)\n",
    "    EfficientNetB0_trained_model.load_state_dict(torch.load(f\"/kaggle/working/Models/efficientnet_b5_checkpoint_fold_{fold}.pt\"))\n",
    "    EfficientNetB0_trained_model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, data in enumerate(validation_dataloader):\n",
    "            data[\"image\"], data['targets'] = data[\"image\"].to(Config.DEVICE, dtype=torch.float), data['targets'].to(Config.DEVICE, dtype=torch.float)    \n",
    "            y_logits = EfficientNetB0_trained_model(data['image']).squeeze(dim=0)\n",
    "            valid_probs = torch.sigmoid(y_logits).detach().cpu().numpy().tolist()\n",
    "            valid_predictions.extend(valid_probs)\n",
    "    valid_auc = roc_auc_score(y_true=validation_targets, y_score=valid_predictions)\n",
    "    print(valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:32.597206Z",
     "iopub.status.busy": "2023-04-14T03:47:32.596186Z",
     "iopub.status.idle": "2023-04-14T03:47:32.607531Z",
     "shell.execute_reply": "2023-04-14T03:47:32.606455Z",
     "shell.execute_reply.started": "2023-04-14T03:47:32.597154Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_on_test(fold):\n",
    "    test_dataset = DatasetRetriever(df=test_df, tabular_features=None, use_tabular_features=False, \n",
    "                     augmentations=validation_augmentations, is_test=True)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=Config.VAL_BATCH_SIZE,\n",
    "                                       shuffle=False, num_workers=os.cpu_count())\n",
    "    test_predictions = []\n",
    "    if torch.cuda.device_count() in (0,1):\n",
    "        EfficientNetB0_trained_model = Model().to(Config.DEVICE)\n",
    "    elif torch.cuda.device_count() > 1:\n",
    "        EfficientNetB0_trained_model = Model().to(Config.DEVICE)\n",
    "        EfficientNetB0_trained_model = nn.DataParallel(EfficientNetB0_trained_model)\n",
    "    EfficientNetB0_trained_model.load_state_dict(torch.load(f\"/kaggle/working/Models/efficientnet_b5_checkpoint_fold_{fold}.pt\"))   \n",
    "    EfficientNetB0_trained_model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, data in enumerate(test_dataloader):\n",
    "            data[\"image\"] = data[\"image\"].to(Config.DEVICE, dtype=torch.float)    \n",
    "            y_logits = EfficientNetB0_trained_model(data['image']).squeeze(dim=0)\n",
    "            test_probs = torch.sigmoid(y_logits).detach().cpu().numpy()\n",
    "            test_predictions.extend(test_probs)\n",
    "    submission_df = pd.read_csv(Config.submission_csv_path)\n",
    "    test_predictions = [test_predictions[img].item() for img in range(len(test_predictions))]\n",
    "    submission_df['target'] = test_predictions\n",
    "    submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-04-14T03:47:33.137200Z",
     "iopub.status.busy": "2023-04-14T03:47:33.136003Z",
     "iopub.status.idle": "2023-04-14T09:09:55.227497Z",
     "shell.execute_reply": "2023-04-14T09:09:55.224892Z",
     "shell.execute_reply.started": "2023-04-14T03:47:33.137148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b5-b6417697.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e23dce0fd624240b9047835d610022e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/117M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using meta features\n",
      "Not using meta features\n",
      "Validation loss decreased (inf --> 0.071890).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [53:24<16:54:51, 3204.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 | train_loss : 0.0986 | valid_loss : 0.0719 | valid_auc : 0.8579 \n",
      "Not using meta features\n",
      "Not using meta features\n",
      "Validation loss decreased (0.071890 --> 0.067238).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [1:45:19<15:45:30, 3151.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 | train_loss : 0.0749 | valid_loss : 0.0672 | valid_auc : 0.8902 \n",
      "Not using meta features\n",
      "Not using meta features\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [2:39:52<15:08:39, 3207.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 | train_loss : 0.0708 | valid_loss : 0.0709 | valid_auc : 0.8746 \n",
      "Not using meta features\n",
      "Not using meta features\n",
      "Validation loss decreased (0.067238 --> 0.065598).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [3:34:50<14:24:50, 3243.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 | train_loss : 0.0706 | valid_loss : 0.0656 | valid_auc : 0.8971 \n",
      "Not using meta features\n",
      "Not using meta features\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [4:28:53<13:30:42, 3242.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 | train_loss : 0.0683 | valid_loss : 0.0673 | valid_auc : 0.9015 \n",
      "Not using meta features\n",
      "Not using meta features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [5:22:17<16:06:52, 3867.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 2\n",
      "Early Stopping\n",
      "Total training time: 19337.441 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_model(fold=0, train_df=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T09:09:55.232027Z",
     "iopub.status.busy": "2023-04-14T09:09:55.231023Z",
     "iopub.status.idle": "2023-04-14T09:12:07.127936Z",
     "shell.execute_reply": "2023-04-14T09:12:07.126715Z",
     "shell.execute_reply.started": "2023-04-14T09:09:55.231981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n",
      "0.897142585912284\n"
     ]
    }
   ],
   "source": [
    "validate(fold=0, train_df=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T09:12:09.085934Z",
     "iopub.status.busy": "2023-04-14T09:12:09.084999Z",
     "iopub.status.idle": "2023-04-14T09:15:52.801947Z",
     "shell.execute_reply": "2023-04-14T09:15:52.800667Z",
     "shell.execute_reply.started": "2023-04-14T09:12:09.085882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "predict_on_test(fold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model gave a score of 0.8928 on private leadeboard & 0.8942 on public leaderboard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
